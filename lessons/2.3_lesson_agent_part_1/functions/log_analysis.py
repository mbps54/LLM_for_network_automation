import json
import streamlit as st
from pydantic import BaseModel
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser


def log_analysis_main():
    st.title("AI Assistant ‚Äî Logs analyzer")

    model_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4o"]
    )

    # ---------------------------- STRUCT ----------------------------

    class LogEntry(BaseModel):
        message: str
        severity: str  # –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: low, mid, high

    parser = PydanticOutputParser(pydantic_object=LogEntry)

    # ---------------------------- PROMPTS ----------------------------

    SEVERITY_PROMPT = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ª–æ–≥–æ–≤ —Å–µ—Ç–µ–≤–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è Cisco Systems.\n"
        "–û–ø—Ä–µ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è: 'low', 'mid' –∏–ª–∏ 'high'.\n"
        "–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –Ω–∏–∂–µ (JSON):\n\n"
        "{{" + parser.get_format_instructions().replace("{", "{{").replace("}", "}}") + "}}"
    )

    EXPLANATION_PROMPT = (
        "–¢—ã —Å–µ—Ç–µ–≤–æ–π –∏–Ω–∂–µ–Ω–µ—Ä —Å –æ–ø—ã—Ç–æ–º –≤ Cisco IOS.\n"
        "–û–±—ä—è—Å–Ω–∏ –ª–æ–≥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.\n"
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç? –ö–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ? –ß—Ç–æ –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å?\n"
        "–û–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π, –±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
    )

    # ---------------------------- LLM ----------------------------

    llm = init_chat_model(
        model_name,
        model_provider="openai",
        temperature=0.7,
    )

    # ---------------------------- LOAD LOGS ----------------------------

    if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–≥–∏"):
        try:
            with open("logs/logs.json", "r") as file:
                logs = json.load(file)
            st.session_state["logs"] = logs
            st.session_state["severity_done"] = False
            st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(logs)}")
        except Exception as error:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ª–æ–≥–æ–≤: {error}")

    if "logs" in st.session_state:
        logs = st.session_state["logs"]

    # ---------------------------- SEVERITY ----------------------------

        if st.button("–û—Ü–µ–Ω–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤"):
            with st.spinner("–û—Ü–µ–Ω–∏–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å..."):
                severity_prompt = ChatPromptTemplate.from_messages([
                    ("system", SEVERITY_PROMPT),
                    ("user", "{log}")
                ])
                chain = severity_prompt | llm | parser

                severity_map = {}

                for log in logs:
                    try:
                        item_descriptions = [
                            f'IP: {item["ip"]}, Count: {item["count"]}, Message: {item["message"]}'
                            for item in log["items"]
                        ]
                        combined_items = "\n".join(item_descriptions)
                        input_msg = (
                            f'Event Type: {log["event_type"]}\n'
                            f'Total Count: {log["count"]}\n'
                            f'Items:\n{combined_items}'
                        )

                        result = chain.invoke({"log": input_msg})
                        severity_map[log["event_type"]] = result.severity
                    except Exception as e:
                        severity_map[log["event_type"]] = "n/a"
                        st.warning(f"–û—à–∏–±–∫–∞ –¥–ª—è event_type '{log['event_type']}': {e}")

                for log in logs:
                    log["severity"] = severity_map.get(log["event_type"], "n/a")

                st.session_state["severity_done"] = True

        # ---------------------------- SORTING ----------------------------

        sort_by = st.radio("–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ:", ["–ß–∞—Å—Ç–æ—Ç–µ", "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏"])

        if sort_by == "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏":
            if not st.session_state.get("severity_done"):
                st.warning("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –ª–æ–≥–æ–≤")
                return
            logs.sort(
                key=lambda x: {"high": 0, "mid": 1, "low": 2}.get(x.get("severity", "mid"), 1)
            )
        else:
            logs.sort(key=lambda x: x["count"], reverse=True)

        # ---------------------------- DISPLAY ----------------------------

        messages_list = [f'{i + 1}. {log["event_type"]}' for i, log in enumerate(logs)]

        for index, log in enumerate(logs, start=1):
            event_type = log["event_type"]
            example = log["items"][0]["message"] if log["items"] else "(–Ω–µ—Ç –ø—Ä–∏–º–µ—Ä–∞)"
            ips = ", ".join({item["ip"] for item in log["items"]})
            count = log["count"]
            severity = log.get("severity", "‚Äî")

            st.markdown(f"""
            <div style="font-size: 16px; line-height: 1.4; margin-bottom: 6px;">
                <b>N:</b> {index}<br>
                <b>Event type:</b> {event_type}<br>
                <b>Example:</b> {example}<br>
                <b>Devices:</b> {ips}<br>
                <b>Count:</b> {count}<br>
                <b>Severity:</b> {severity}
            </div>
            <hr style="margin: 6px 0;">
            """, unsafe_allow_html=True)

        # ---------------------------- ANALYZE SELECTED ----------------------------

        selected_index = messages_list.index(
            st.selectbox("üîç –í—ã–±–µ—Ä–∏—Ç–µ –ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", messages_list)
        )
        selected_info = logs[selected_index]

        if selected_info and st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
            event_type = selected_info["event_type"]
            count = selected_info["count"]

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –≤–≤–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö items
            item_lines = [
                f"IP: {item['ip']}, Count: {item['count']}, Message: {item['message']}"
                for item in selected_info["items"]
            ]
            items_text = "\n".join(item_lines)

            full_context = (
                f"–¢–∏–ø —Å–æ–±—ã—Ç–∏—è: {event_type}\n"
                f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {count}\n"
                f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º:\n{items_text}"
            )

            explanation_prompt = ChatPromptTemplate.from_messages([
                ("system", EXPLANATION_PROMPT),
                ("user", "{input_text}")
            ])
            explanation_chain = explanation_prompt | llm
            try:
                response = explanation_chain.invoke({"input_text": full_context})
                st.subheader("üí° –ê–Ω–∞–ª–∏–∑ –æ—Ç LLM:")
                st.write(response.content)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
